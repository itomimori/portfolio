InsureLLM RAG QA Assistant
このプロジェクトは、Retrieval-Augmented Generation (RAG) を用いて、保険会社「Insurellm」に関するドキュメントから質問に答えるチャットアシスタントを構築します。LangChain、ChromaDB、OpenAI モデルを組み合わせて、指定されたドキュメントに基づいて正確かつ文脈に沿った回答を提供します。

主な機能
複数のドキュメント形式のサポート: PDF, DOCX, XLSX, TXT, Markdown (.md) ファイルを処理できます。

効率的なデータ処理: ドキュメントを小さなチャンクに分割し、重複排除と一意の ID 付けを行います。

ベクターデータベースの管理: ChromaDB を使用して、ドキュメントチャンクの埋め込みを永続化し、新しいドキュメントが追加された場合にのみデータベースを再構築します。

ベクターデータの可視化: t-SNE アルゴリズムを使用して、高次元のドキュメント埋め込みを 2D または 3D 空間で視覚化し、データポイントの関係性を理解するのに役立ちます。

高度な検索: 検索されたドキュメントの関連性スコアに基づいてフィルタリングするカスタムリトリーバーを実装しています。

会話履歴対応: ユーザーの過去の会話履歴を考慮して、関連性の高いドキュメントを検索し、文脈に沿った回答を生成します。

Gradio インターフェース: 簡単で直感的な Web ベースのチャットインターフェースを提供し、アシスタントと対話できます。

セットアップ
前提条件
Python 3.9 以上

OpenAI API キー

インストール
必要なライブラリをインストールします。

pip install -r requirements.txt

環境設定
プロジェクトのルートディレクトリに.env ファイルを作成し、OpenAI API キーを設定します。
OPENAI_API_KEY="your_openai_api_key"

データディレクトリの準備
処理したいドキュメントを格納するためのデータディレクトリを作成し、DATA_PATH を設定します。

例:DATA_PATH = r"path/to/your/documents"

注意事項
ドキュメントの正確性: アシスタントの応答は、提供されたドキュメントの品質と内容に厳密に依存します。ドキュメントに情報がなければ、アシスタントは「情報がありません」と回答します。

API キーの管理: OPENAI_API_KEY は安全に保管し、バージョン管理システムにコミットしないでください。

ChromaDB: .env で定義されたパスに ChromaDB のベクターデータが保存されます。同じドキュメントセットでスクリプトを再実行しても、データベースが変更されていなければ再構築は行われません。

実行例
![alt text](image.png)
![alt text](image-1.png)
